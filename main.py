import pandas as pd
import logging
import argparse
import sys
from pathlib import Path
import os

# Ajouter le r√©pertoire src au PYTHONPATH
sys.path.append(str(Path(__file__).parent / 'src'))

# Ajouter √©galement le r√©pertoire courant
sys.path.append(str(Path(__file__).parent))

try:
    from src.data_collection.db_collector import ElectionDBCollector
    from src.data_processing.election_processor import ElectionDataProcessor
    from src.models.election_models import ElectionPredictor
    from src.visualization.analyzer import ElectionAnalyzer
    from config.config import DATA_CONFIG, MODEL_CONFIG
except ImportError as e:
    print(f"‚ùå Erreur d'import: {e}")
    print("üìÅ V√©rifiez que tous les dossiers et fichiers sont pr√©sents:")
    print("   - config/config.py")
    print("   - src/data_collection/db_collector.py") 
    print("   - src/data_processing/election_processor.py")
    print("   - src/models/election_models.py")
    print("   - src/visualization/analyzer.py")
    sys.exit(1)

# Configuration du logging
def setup_logging():
    """Configure le syst√®me de logging"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # Configuration des handlers
    handlers = [
        logging.StreamHandler(sys.stdout),  # Sortie console
        logging.FileHandler('election_predictor.log', encoding='utf-8')  # Fichier log
    ]
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=handlers
    )
    
    # R√©duire le niveau de logging pour certains modules
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('plotly').setLevel(logging.WARNING)

setup_logging()
logger = logging.getLogger(__name__)

def check_directories():
    """V√©rifie et cr√©e les r√©pertoires n√©cessaires"""
    directories = [
        'data/raw',
        'data/processed', 
        'models',
        'visualizations',
        'logs'
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        logger.info(f"üìÅ R√©pertoire v√©rifi√©/cr√©√©: {directory}")

def safe_format_number(value, format_str=".3f", default="N/A"):
    """Formate un nombre de mani√®re s√©curis√©e"""
    try:
        if value is None:
            return default
        if isinstance(value, str) and value == 'N/A':
            return default
        return f"{value:{format_str}}"
    except (ValueError, TypeError):
        return default

def main():
    """Fonction principale du pipeline"""
    parser = argparse.ArgumentParser(
        description='üó≥Ô∏è Mod√®le pr√©dictif √©lections Occitanie',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python main.py --all          # Pipeline complet
  python main.py --collect      # Collecter les donn√©es uniquement
  python main.py --train        # Entra√Æner les mod√®les uniquement
  python main.py --analyze      # Cr√©er les visualisations uniquement
  python main.py --predict      # Faire des pr√©dictions uniquement
        """
    )
    
    parser.add_argument('--collect', action='store_true', 
                       help='Collecter et traiter les donn√©es')
    parser.add_argument('--train', action='store_true', 
                       help='Entra√Æner les mod√®les de machine learning')
    parser.add_argument('--analyze', action='store_true', 
                       help='Cr√©er les analyses et visualisations')
    parser.add_argument('--predict', action='store_true', 
                       help='Faire des pr√©dictions avec le mod√®le')
    parser.add_argument('--all', action='store_true', 
                       help='Ex√©cuter tout le pipeline complet')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Mode verbose pour plus de d√©tails')
    
    args = parser.parse_args()
    
    # Configuration du niveau de logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Si aucun argument ou --all, ex√©cuter tout le pipeline
    if not any([args.collect, args.train, args.analyze, args.predict]) or args.all:
        args.collect = args.train = args.analyze = True
        logger.info("üöÄ Ex√©cution du pipeline complet")
    
    try:
        logger.info("=" * 60)
        logger.info("üó≥Ô∏è D√âMARRAGE DU PIPELINE √âLECTIONS OCCITANIE")
        logger.info("=" * 60)
        logger.info(f"üë§ Utilisateur: {os.getenv('USER', os.getenv('USERNAME', 'mgaisnon'))}")
        logger.info(f"üìÖ Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # V√©rification des r√©pertoires
        check_directories()
        
        # Variables pour suivre l'√©tat
        processed_df = None
        predictor = None
        
        # 1. COLLECTE ET TRAITEMENT DES DONN√âES
        if args.collect:
            logger.info("=" * 40)
            logger.info("üìä √âTAPE 1: COLLECTE DES DONN√âES")
            logger.info("=" * 40)
            
            try:
                collector = ElectionDBCollector()
                raw_df = collector.get_election_data()
                
                if raw_df.empty:
                    logger.warning("‚ö†Ô∏è Aucune donn√©e collect√©e, utilisation des donn√©es d'exemple")
                    # Forcer la cr√©ation de donn√©es d'exemple
                    collector._create_sample_data()
                    raw_df = collector.sample_data
                else:
                    logger.info(f"‚úÖ Collect√© {len(raw_df):,} enregistrements")
                
                # Sauvegarde des donn√©es brutes
                raw_path = Path('data/raw/election_data_raw.csv')
                raw_df.to_csv(raw_path, index=False, encoding='utf-8')
                logger.info(f"üíæ Donn√©es brutes sauvegard√©es: {raw_path}")
                
                # Traitement des donn√©es
                logger.info("üîÑ Traitement des donn√©es...")
                processor = ElectionDataProcessor()
                processed_df = processor.process_election_results(raw_df)
                
                logger.info(f"‚úÖ Donn√©es trait√©es: {processed_df.shape}")
                logger.info(f"   - D√©partements: {processed_df['departement'].nunique()}")
                logger.info(f"   - Ann√©es: {sorted(processed_df['annee'].unique())}")
                logger.info(f"   - Nuances: {processed_df['nuance'].nunique()}")
                
                # Sauvegarde des donn√©es trait√©es
                processed_path = Path('data/processed/election_data_processed.csv')
                processed_df.to_csv(processed_path, index=False, encoding='utf-8')
                logger.info(f"üíæ Donn√©es trait√©es sauvegard√©es: {processed_path}")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la collecte: {e}")
                logger.info("üîÑ Tentative de chargement des donn√©es existantes...")
                
                # Essayer de charger des donn√©es existantes
                processed_path = Path('data/processed/election_data_processed.csv')
                if processed_path.exists():
                    processed_df = pd.read_csv(processed_path)
                    logger.info(f"‚úÖ Donn√©es existantes charg√©es: {processed_df.shape}")
                else:
                    logger.error("‚ùå Aucune donn√©e disponible")
                    return
        
        # Chargement des donn√©es pour les autres √©tapes
        if not args.collect and processed_df is None:
            logger.info("üìÇ Chargement des donn√©es existantes...")
            processed_path = Path('data/processed/election_data_processed.csv')
            
            if processed_path.exists():
                processed_df = pd.read_csv(processed_path)
                logger.info(f"‚úÖ Donn√©es charg√©es: {processed_df.shape}")
            else:
                logger.error("‚ùå Aucune donn√©e trouv√©e. Lancez d'abord avec --collect")
                return
        
        if processed_df is None or processed_df.empty:
            logger.error("‚ùå Aucune donn√©e disponible pour continuer")
            return
        
        # 2. ENTRA√éNEMENT DES MOD√àLES
        if args.train:
            logger.info("=" * 40)
            logger.info("ü§ñ √âTAPE 2: ENTRA√éNEMENT DES MOD√àLES")
            logger.info("=" * 40)
            
            try:
                processor = ElectionDataProcessor()
                X, y = processor.prepare_ml_features(processed_df)
                
                if X.empty or y.empty:
                    logger.error("‚ùå Impossible de pr√©parer les features pour le ML")
                    logger.info("üí° V√©rifiez la qualit√© des donn√©es")
                    return
                
                logger.info(f"üìä Features pr√©par√©es: {X.shape}")
                logger.info(f"üéØ Target pr√©par√©e: {y.shape}")
                logger.info(f"üìã Colonnes features: {list(X.columns)}")
                
                # Initialisation et entra√Ænement des mod√®les
                predictor = ElectionPredictor()
                predictor.initialize_models()
                
                logger.info(f"üè≠ Entra√Ænement de {len(predictor.models)} mod√®les...")
                results = predictor.train_models(X, y)
                
                # Affichage des r√©sultats
                print("\n" + "=" * 60)
                print("üìà R√âSULTATS DES MOD√àLES")
                print("=" * 60)
                
                successful_models = 0
                for name, result in results.items():
                    if 'error' not in result:
                        accuracy = result.get('accuracy', 0)
                        cv_mean = result.get('cv_mean', 0)
                        cv_std = result.get('cv_std', 0)
                        auc = result.get('auc_score')
                        
                        # ‚úÖ Formatage s√©curis√© du score AUC
                        auc_str = ""
                        if auc is not None and auc != 'N/A':
                            auc_str = f" | AUC: {safe_format_number(auc)}"
                        
                        accuracy_str = safe_format_number(accuracy)
                        cv_mean_str = safe_format_number(cv_mean)
                        cv_std_str = safe_format_number(cv_std)
                        
                        print(f"üî∏ {name:20} | Acc: {accuracy_str} | CV: {cv_mean_str}¬±{cv_std_str}{auc_str}")
                        successful_models += 1
                    else:
                        error_msg = str(result['error'])
                        if len(error_msg) > 50:
                            error_msg = error_msg[:47] + "..."
                        print(f"‚ùå {name:20} | Erreur: {error_msg}")
                
                print(f"\n‚úÖ Mod√®les entra√Æn√©s avec succ√®s: {successful_models}/{len(results)}")
                
                if predictor.best_model is not None:
                    print(f"üèÜ Meilleur mod√®le: {predictor.best_model_name}")
                    print(f"üéØ Score CV: {safe_format_number(predictor.best_score)}")
                    
                    # Optimisation des hyperparam√®tres
                    logger.info("‚öôÔ∏è Optimisation des hyperparam√®tres...")
                    try:
                        optimization_results = predictor.optimize_best_model(X, y)
                        if optimization_results and 'best_score' in optimization_results:
                            improvement = optimization_results.get('score_improvement', 0)
                            best_score_str = safe_format_number(optimization_results['best_score'])
                            improvement_str = safe_format_number(improvement, "+.3f")
                            
                            print(f"üìà Score apr√®s optimisation: {best_score_str}")
                            print(f"üìä Am√©lioration: {improvement_str}")
                            
                            if optimization_results.get('best_params'):
                                print("üîß Meilleurs param√®tres:")
                                for param, value in optimization_results['best_params'].items():
                                    print(f"   - {param}: {value}")
                        else:
                            logger.info("‚ÑπÔ∏è Optimisation non disponible pour ce mod√®le")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Optimisation √©chou√©e: {e}")
                    
                    # Importance des features
                    try:
                        importance_df = predictor.get_feature_importance(X.columns.tolist())
                        if not importance_df.empty:
                            print("\nüîç TOP 10 VARIABLES IMPORTANTES")
                            print("-" * 40)
                            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):
                                importance_str = safe_format_number(row['importance'])
                                print(f"{i:2d}. {row['feature']:20} | {importance_str}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Calcul importance √©chou√©: {e}")
                    
                    # Sauvegarde du mod√®le
                    try:
                        model_path = 'best_election_model.pkl'
                        predictor.save_model(model_path)
                        logger.info(f"üíæ Mod√®le sauvegard√©: models/{model_path}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Sauvegarde √©chou√©e: {e}")
                    
                else:
                    logger.error("‚ùå Aucun mod√®le n'a pu √™tre entra√Æn√© avec succ√®s")
                    return
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
                import traceback
                logger.error(traceback.format_exc())
                return
        
        # 3. ANALYSES ET VISUALISATIONS
        if args.analyze:
            logger.info("=" * 40)
            logger.info("üìä √âTAPE 3: ANALYSES ET VISUALISATIONS")
            logger.info("=" * 40)
            
            try:
                analyzer = ElectionAnalyzer()
                analyses_results = {}
                
                # Chargement du mod√®le si pas d√©j√† en m√©moire
                if not args.train:
                    try:
                        predictor = ElectionPredictor()
                        predictor.load_model('best_election_model.pkl')
                        logger.info("‚úÖ Mod√®le charg√© pour l'analyse")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Impossible de charger le mod√®le: {e}")
                        predictor = None
                
                # Analyse de corr√©lation
                logger.info("üîó Cr√©ation de l'analyse de corr√©lation...")
                try:
                    corr_analysis = analyzer.create_correlation_analysis(processed_df)
                    if corr_analysis:
                        analyses_results['correlation'] = corr_analysis
                        logger.info(f"‚úÖ Analyse de corr√©lation cr√©√©e: {corr_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Analyse corr√©lation √©chou√©e: {e}")
                
                # Analyse g√©ographique
                logger.info("üó∫Ô∏è Cr√©ation de l'analyse g√©ographique...")
                try:
                    geo_analysis = analyzer.create_geographic_analysis(processed_df)
                    if geo_analysis:
                        analyses_results['geographic'] = geo_analysis
                        logger.info(f"‚úÖ Analyse g√©ographique cr√©√©e: {geo_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Analyse g√©ographique √©chou√©e: {e}")
                
                # Analyse temporelle
                logger.info("üìà Cr√©ation de l'analyse temporelle...")
                try:
                    temporal_analysis = analyzer.create_temporal_analysis(processed_df)
                    if temporal_analysis:
                        analyses_results['temporal'] = temporal_analysis
                        logger.info(f"‚úÖ Analyse temporelle cr√©√©e: {temporal_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Analyse temporelle √©chou√©e: {e}")
                
                # Dashboard interactif
                logger.info("üéõÔ∏è Cr√©ation du dashboard interactif...")
                try:
                    interactive_fig = analyzer.create_interactive_dashboard(processed_df)
                    if interactive_fig:
                        analyses_results['interactive'] = {'plots_created': ['interactive_dashboard.html']}
                        logger.info("‚úÖ Dashboard interactif cr√©√©")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Dashboard interactif √©chou√©: {e}")
                
                # Analyse de performance si mod√®le disponible
                if predictor and predictor.best_model is not None:
                    logger.info("üéØ Cr√©ation de l'analyse de performance...")
                    try:
                        processor = ElectionDataProcessor()
                        X, y = processor.prepare_ml_features(processed_df)
                        if not X.empty and not y.empty:
                            perf_analysis = analyzer.create_performance_dashboard(predictor, X, y)
                            if perf_analysis:
                                analyses_results['performance'] = perf_analysis
                                logger.info("‚úÖ Analyse de performance cr√©√©e")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Analyse performance √©chou√©e: {e}")
                
                # G√©n√©ration du rapport HTML
                if analyses_results:
                    logger.info("üìã G√©n√©ration du rapport final...")
                    try:
                        report_path = analyzer.generate_report(analyses_results)
                        
                        print("\n" + "=" * 60)
                        print("üìä ANALYSES CR√â√âES")
                        print("=" * 60)
                        
                        total_plots = 0
                        for analysis_name, results in analyses_results.items():
                            plots = results.get('plots_created', [])
                            total_plots += len(plots)
                            print(f"üî∏ {analysis_name:15} | {len(plots)} visualisation(s)")
                            for plot in plots:
                                print(f"   üìÑ {plot}")
                        
                        print(f"\n‚úÖ Total visualisations: {total_plots}")
                        print(f"üìÅ R√©pertoire: visualizations/")
                        
                        if report_path:
                            print(f"üìã Rapport complet: {report_path}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è G√©n√©ration rapport √©chou√©e: {e}")
                
                else:
                    logger.warning("‚ö†Ô∏è Aucune analyse n'a pu √™tre cr√©√©e")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'analyse: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        # 4. PR√âDICTIONS
        if args.predict:
            logger.info("=" * 40)
            logger.info("üîÆ √âTAPE 4: PR√âDICTIONS")
            logger.info("=" * 40)
            
            try:
                # Chargement du mod√®le
                if predictor is None:
                    predictor = ElectionPredictor()
                    predictor.load_model('best_election_model.pkl')
                
                # Pr√©paration des donn√©es pour pr√©diction
                processor = ElectionDataProcessor()
                X, y = processor.prepare_ml_features(processed_df)
                
                if not X.empty:
                    # Pr√©diction sur un √©chantillon
                    sample_size = min(10, len(X))
                    sample_X = X.sample(n=sample_size, random_state=42)
                    
                    predictions, probabilities = predictor.predict(sample_X)
                    
                    print(f"\nüîÆ EXEMPLES DE PR√âDICTIONS ({sample_size} √©chantillons)")
                    print("-" * 60)
                    
                    for i, idx in enumerate(sample_X.index):
                        pred = predictions[i]
                        conf_str = ""
                        
                        if probabilities is not None:
                            confidence = probabilities[i].max()
                            conf_str = f" (confiance: {confidence:.1%})"
                        
                        # D√©coder la pr√©diction si n√©cessaire
                        if hasattr(predictor, 'label_encoders') and 'winner' in predictor.label_encoders:
                            try:
                                pred_decoded = predictor.label_encoders['winner'].inverse_transform([pred])[0]
                                print(f"üéØ √âchantillon {idx:3d}: {pred_decoded}{conf_str}")
                            except:
                                print(f"üéØ √âchantillon {idx:3d}: Classe {pred}{conf_str}")
                        else:
                            print(f"üéØ √âchantillon {idx:3d}: {pred}{conf_str}")
                    
                    # Statistiques des pr√©dictions
                    if probabilities is not None:
                        avg_confidence = probabilities.max(axis=1).mean()
                        high_conf_count = (probabilities.max(axis=1) > 0.8).sum()
                        
                        print(f"\nüìä Statistiques des pr√©dictions:")
                        print(f"   - Confiance moyenne: {avg_confidence:.1%}")
                        print(f"   - Pr√©dictions haute confiance (>80%): {high_conf_count}/{sample_size}")
                
                else:
                    logger.error("‚ùå Impossible de pr√©parer les donn√©es pour la pr√©diction")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors des pr√©dictions: {e}")
                logger.info("üí° Assurez-vous qu'un mod√®le a √©t√© entra√Æn√© (--train)")
        
        # R√©sum√© final
        logger.info("=" * 60)
        logger.info("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS")
        logger.info("=" * 60)
        
        # Statistiques finales
        if processed_df is not None:
            print(f"\nüìä R√âSUM√â FINAL")
            print("-" * 30)
            print(f"üìã Enregistrements trait√©s: {len(processed_df):,}")
            print(f"üèõÔ∏è D√©partements couverts: {processed_df['departement'].nunique()}")
            print(f"üìÖ Ann√©es disponibles: {sorted(processed_df['annee'].unique())}")
            print(f"üé≠ Nuances politiques: {processed_df['nuance'].nunique()}")
        
        print(f"\nüìÅ Fichiers g√©n√©r√©s:")
        print(f"   - Donn√©es: data/processed/")
        if args.train:
            print(f"   - Mod√®les: models/")
        if args.analyze:
            print(f"   - Visualisations: visualizations/")
        print(f"   - Logs: election_predictor.log")
        
        print(f"\nüöÄ √âtapes suivantes:")
        print(f"   - Lancez: streamlit run app.py")
        print(f"   - Ouvrez: http://localhost:8501")
        
        logger.info(f"üéâ Pipeline termin√© pour l'utilisateur: mgaisnon")
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Pipeline interrompu par l'utilisateur")
        print("\n‚èπÔ∏è Pipeline interrompu.")
        
    except Exception as e:
        logger.error(f"üí• Erreur fatale dans le pipeline: {e}")
        import traceback
        logger.error(traceback.format_exc())
        print(f"\n‚ùå Erreur fatale: {e}")
        print("üìã Consultez le fichier election_predictor.log pour plus de d√©tails")
        raise

if __name__ == "__main__":
    main()