import pandas as pd
import logging
import argparse
import sys
from pathlib import Path
import os

# Ajouter le rÃ©pertoire src au PYTHONPATH
sys.path.append(str(Path(__file__).parent / 'src'))

# Ajouter Ã©galement le rÃ©pertoire courant
sys.path.append(str(Path(__file__).parent))

try:
    from src.data_collection.db_collector import ElectionDBCollector
    from src.data_processing.election_processor import ElectionDataProcessor
    from src.models.election_models import ElectionPredictor
    from src.visualization.analyzer import ElectionAnalyzer
    from config.config import DATA_CONFIG, MODEL_CONFIG
except ImportError as e:
    print(f"âŒ Erreur d'import: {e}")
    print("ğŸ“ VÃ©rifiez que tous les dossiers et fichiers sont prÃ©sents:")
    print("   - config/config.py")
    print("   - src/data_collection/db_collector.py") 
    print("   - src/data_processing/election_processor.py")
    print("   - src/models/election_models.py")
    print("   - src/visualization/analyzer.py")
    sys.exit(1)

# Configuration du logging
def setup_logging():
    """Configure le systÃ¨me de logging"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # Configuration des handlers
    handlers = [
        logging.StreamHandler(sys.stdout),  # Sortie console
        logging.FileHandler('election_predictor.log', encoding='utf-8')  # Fichier log
    ]
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=handlers
    )
    
    # RÃ©duire le niveau de logging pour certains modules
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('plotly').setLevel(logging.WARNING)

setup_logging()
logger = logging.getLogger(__name__)

def check_directories():
    """VÃ©rifie et crÃ©e les rÃ©pertoires nÃ©cessaires"""
    directories = [
        'data/raw',
        'data/processed', 
        'models',
        'visualizations',
        'logs'
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ RÃ©pertoire vÃ©rifiÃ©/crÃ©Ã©: {directory}")

def safe_format_number(value, format_str=".3f", default="N/A"):
    """Formate un nombre de maniÃ¨re sÃ©curisÃ©e"""
    try:
        if value is None:
            return default
        if isinstance(value, str) and value == 'N/A':
            return default
        return f"{value:{format_str}}"
    except (ValueError, TypeError):
        return default

def main():
    """Fonction principale du pipeline"""
    parser = argparse.ArgumentParser(
        description='ğŸ—³ï¸ ModÃ¨le prÃ©dictif Ã©lections Occitanie',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python main.py --all          # Pipeline complet
  python main.py --collect      # Collecter les donnÃ©es uniquement
  python main.py --train        # EntraÃ®ner les modÃ¨les uniquement
  python main.py --analyze      # CrÃ©er les visualisations uniquement
  python main.py --predict      # Faire des prÃ©dictions uniquement
        """
    )
    
    parser.add_argument('--collect', action='store_true', 
                       help='Collecter et traiter les donnÃ©es')
    parser.add_argument('--train', action='store_true', 
                       help='EntraÃ®ner les modÃ¨les de machine learning')
    parser.add_argument('--analyze', action='store_true', 
                       help='CrÃ©er les analyses et visualisations')
    parser.add_argument('--predict', action='store_true', 
                       help='Faire des prÃ©dictions avec le modÃ¨le')
    parser.add_argument('--all', action='store_true', 
                       help='ExÃ©cuter tout le pipeline complet')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Mode verbose pour plus de dÃ©tails')
    
    args = parser.parse_args()
    
    # Configuration du niveau de logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Si aucun argument ou --all, exÃ©cuter tout le pipeline
    if not any([args.collect, args.train, args.analyze, args.predict]) or args.all:
        args.collect = args.train = args.analyze = True
        logger.info("ğŸš€ ExÃ©cution du pipeline complet")
    
    try:
        logger.info("=" * 60)
        logger.info("ğŸ—³ï¸ DÃ‰MARRAGE DU PIPELINE Ã‰LECTIONS OCCITANIE")
        logger.info("=" * 60)
        logger.info(f"ğŸ‘¤ Utilisateur: {os.getenv('USER', os.getenv('USERNAME', 'mgaisnon'))}")
        logger.info(f"ğŸ“… Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # VÃ©rification des rÃ©pertoires
        check_directories()
        
        # Variables pour suivre l'Ã©tat
        processed_df = None
        predictor = None
        
        # 1. COLLECTE ET TRAITEMENT DES DONNÃ‰ES
        if args.collect:
            logger.info("=" * 40)
            logger.info("ğŸ“Š Ã‰TAPE 1: COLLECTE DES DONNÃ‰ES")
            logger.info("=" * 40)
            
            try:
                collector = ElectionDBCollector()
                raw_df = collector.get_election_data()
                
                if raw_df.empty:
                    logger.warning("âš ï¸ Aucune donnÃ©e collectÃ©e, utilisation des donnÃ©es d'exemple")
                    # Forcer la crÃ©ation de donnÃ©es d'exemple
                    collector._create_sample_data()
                    raw_df = collector.sample_data
                else:
                    logger.info(f"âœ… CollectÃ© {len(raw_df):,} enregistrements")
                
                # Sauvegarde des donnÃ©es brutes
                raw_path = Path('data/raw/election_data_raw.csv')
                raw_df.to_csv(raw_path, index=False, encoding='utf-8')
                logger.info(f"ğŸ’¾ DonnÃ©es brutes sauvegardÃ©es: {raw_path}")
                
                # Traitement des donnÃ©es
                logger.info("ğŸ”„ Traitement des donnÃ©es...")
                processor = ElectionDataProcessor()
                processed_df = processor.process_election_results(raw_df)
                
                logger.info(f"âœ… DonnÃ©es traitÃ©es: {processed_df.shape}")
                logger.info(f"   - DÃ©partements: {processed_df['departement'].nunique()}")
                logger.info(f"   - AnnÃ©es: {sorted(processed_df['annee'].unique())}")
                logger.info(f"   - Nuances: {processed_df['nuance'].nunique()}")
                
                # Sauvegarde des donnÃ©es traitÃ©es
                processed_path = Path('data/processed/election_data_processed.csv')
                processed_df.to_csv(processed_path, index=False, encoding='utf-8')
                logger.info(f"ğŸ’¾ DonnÃ©es traitÃ©es sauvegardÃ©es: {processed_path}")
                
            except Exception as e:
                logger.error(f"âŒ Erreur lors de la collecte: {e}")
                logger.info("ğŸ”„ Tentative de chargement des donnÃ©es existantes...")
                
                # Essayer de charger des donnÃ©es existantes
                processed_path = Path('data/processed/election_data_processed.csv')
                if processed_path.exists():
                    processed_df = pd.read_csv(processed_path)
                    logger.info(f"âœ… DonnÃ©es existantes chargÃ©es: {processed_df.shape}")
                else:
                    logger.error("âŒ Aucune donnÃ©e disponible")
                    return
        
        # Chargement des donnÃ©es pour les autres Ã©tapes
        if not args.collect and processed_df is None:
            logger.info("ğŸ“‚ Chargement des donnÃ©es existantes...")
            processed_path = Path('data/processed/election_data_processed.csv')
            
            if processed_path.exists():
                processed_df = pd.read_csv(processed_path)
                logger.info(f"âœ… DonnÃ©es chargÃ©es: {processed_df.shape}")
            else:
                logger.error("âŒ Aucune donnÃ©e trouvÃ©e. Lancez d'abord avec --collect")
                return
        
        if processed_df is None or processed_df.empty:
            logger.error("âŒ Aucune donnÃ©e disponible pour continuer")
            return
        
        # 2. ENTRAÃNEMENT DES MODÃˆLES
        if args.train:
            logger.info("=" * 40)
            logger.info("ğŸ¤– Ã‰TAPE 2: ENTRAÃNEMENT DES MODÃˆLES")
            logger.info("=" * 40)
            
            try:
                processor = ElectionDataProcessor()
                X, y = processor.prepare_ml_features(processed_df)
                
                if X.empty or y.empty:
                    logger.error("âŒ Impossible de prÃ©parer les features pour le ML")
                    logger.info("ğŸ’¡ VÃ©rifiez la qualitÃ© des donnÃ©es")
                    return
                
                logger.info(f"ğŸ“Š Features prÃ©parÃ©es: {X.shape}")
                logger.info(f"ğŸ¯ Target prÃ©parÃ©e: {y.shape}")
                logger.info(f"ğŸ“‹ Colonnes features: {list(X.columns)}")
                
                # Initialisation et entraÃ®nement des modÃ¨les
                predictor = ElectionPredictor()
                predictor.initialize_models()
                
                logger.info(f"ğŸ­ EntraÃ®nement de {len(predictor.models)} modÃ¨les...")
                results = predictor.train_models(X, y)
                
                # Affichage des rÃ©sultats
                print("\n" + "=" * 60)
                print("ğŸ“ˆ RÃ‰SULTATS DES MODÃˆLES")
                print("=" * 60)
                
                successful_models = 0
                for name, result in results.items():
                    if 'error' not in result:
                        accuracy = result.get('accuracy', 0)
                        cv_mean = result.get('cv_mean', 0)
                        cv_std = result.get('cv_std', 0)
                        auc = result.get('auc_score')
                        
                        # âœ… Formatage sÃ©curisÃ© du score AUC
                        auc_str = ""
                        if auc is not None and auc != 'N/A':
                            auc_str = f" | AUC: {safe_format_number(auc)}"
                        
                        accuracy_str = safe_format_number(accuracy)
                        cv_mean_str = safe_format_number(cv_mean)
                        cv_std_str = safe_format_number(cv_std)
                        
                        print(f"ğŸ”¸ {name:20} | Acc: {accuracy_str} | CV: {cv_mean_str}Â±{cv_std_str}{auc_str}")
                        successful_models += 1
                    else:
                        error_msg = str(result['error'])
                        if len(error_msg) > 50:
                            error_msg = error_msg[:47] + "..."
                        print(f"âŒ {name:20} | Erreur: {error_msg}")
                
                print(f"\nâœ… ModÃ¨les entraÃ®nÃ©s avec succÃ¨s: {successful_models}/{len(results)}")
                
                if predictor.best_model is not None:
                    print(f"ğŸ† Meilleur modÃ¨le: {predictor.best_model_name}")
                    print(f"ğŸ¯ Score CV: {safe_format_number(predictor.best_score)}")
                    
                    # Optimisation des hyperparamÃ¨tres
                    logger.info("âš™ï¸ Optimisation des hyperparamÃ¨tres...")
                    try:
                        optimization_results = predictor.optimize_best_model(X, y)
                        if optimization_results and 'best_score' in optimization_results:
                            improvement = optimization_results.get('score_improvement', 0)
                            best_score_str = safe_format_number(optimization_results['best_score'])
                            improvement_str = safe_format_number(improvement, "+.3f")
                            
                            print(f"ğŸ“ˆ Score aprÃ¨s optimisation: {best_score_str}")
                            print(f"ğŸ“Š AmÃ©lioration: {improvement_str}")
                            
                            if optimization_results.get('best_params'):
                                print("ğŸ”§ Meilleurs paramÃ¨tres:")
                                for param, value in optimization_results['best_params'].items():
                                    print(f"   - {param}: {value}")
                        else:
                            logger.info("â„¹ï¸ Optimisation non disponible pour ce modÃ¨le")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Optimisation Ã©chouÃ©e: {e}")
                    
                    # Importance des features
                    try:
                        importance_df = predictor.get_feature_importance(X.columns.tolist())
                        if not importance_df.empty:
                            print("\nğŸ” TOP 10 VARIABLES IMPORTANTES")
                            print("-" * 40)
                            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):
                                importance_str = safe_format_number(row['importance'])
                                print(f"{i:2d}. {row['feature']:20} | {importance_str}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Calcul importance Ã©chouÃ©: {e}")
                    
                    # Sauvegarde du modÃ¨le
                    try:
                        model_path = 'best_election_model.pkl'
                        predictor.save_model(model_path)
                        logger.info(f"ğŸ’¾ ModÃ¨le sauvegardÃ©: models/{model_path}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Sauvegarde Ã©chouÃ©e: {e}")
                    
                else:
                    logger.error("âŒ Aucun modÃ¨le n'a pu Ãªtre entraÃ®nÃ© avec succÃ¨s")
                    return
                
            except Exception as e:
                logger.error(f"âŒ Erreur lors de l'entraÃ®nement: {e}")
                import traceback
                logger.error(traceback.format_exc())
                return
        
        # 3. ANALYSES ET VISUALISATIONS
        if args.analyze:
            logger.info("=" * 40)
            logger.info("ğŸ“Š Ã‰TAPE 3: ANALYSES ET VISUALISATIONS")
            logger.info("=" * 40)
            
            try:
                analyzer = ElectionAnalyzer()
                analyses_results = {}
                
                # Chargement du modÃ¨le si pas dÃ©jÃ  en mÃ©moire
                if not args.train:
                    try:
                        predictor = ElectionPredictor()
                        predictor.load_model('best_election_model.pkl')
                        logger.info("âœ… ModÃ¨le chargÃ© pour l'analyse")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Impossible de charger le modÃ¨le: {e}")
                        predictor = None
                
                # Analyse de corrÃ©lation
                logger.info("ğŸ”— CrÃ©ation de l'analyse de corrÃ©lation...")
                try:
                    corr_analysis = analyzer.create_correlation_analysis(processed_df)
                    if corr_analysis:
                        analyses_results['correlation'] = corr_analysis
                        logger.info(f"âœ… Analyse de corrÃ©lation crÃ©Ã©e: {corr_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Analyse corrÃ©lation Ã©chouÃ©e: {e}")
                
                # Analyse gÃ©ographique
                logger.info("ğŸ—ºï¸ CrÃ©ation de l'analyse gÃ©ographique...")
                try:
                    geo_analysis = analyzer.create_geographic_analysis(processed_df)
                    if geo_analysis:
                        analyses_results['geographic'] = geo_analysis
                        logger.info(f"âœ… Analyse gÃ©ographique crÃ©Ã©e: {geo_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Analyse gÃ©ographique Ã©chouÃ©e: {e}")
                
                # Analyse temporelle
                logger.info("ğŸ“ˆ CrÃ©ation de l'analyse temporelle...")
                try:
                    temporal_analysis = analyzer.create_temporal_analysis(processed_df)
                    if temporal_analysis:
                        analyses_results['temporal'] = temporal_analysis
                        logger.info(f"âœ… Analyse temporelle crÃ©Ã©e: {temporal_analysis.get('plots_created', [])}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Analyse temporelle Ã©chouÃ©e: {e}")
                
                # Dashboard interactif
                logger.info("ğŸ›ï¸ CrÃ©ation du dashboard interactif...")
                try:
                    interactive_fig = analyzer.create_interactive_dashboard(processed_df)
                    if interactive_fig:
                        analyses_results['interactive'] = {'plots_created': ['interactive_dashboard.html']}
                        logger.info("âœ… Dashboard interactif crÃ©Ã©")
                except Exception as e:
                    logger.warning(f"âš ï¸ Dashboard interactif Ã©chouÃ©: {e}")
                
                # Analyse de performance si modÃ¨le disponible
                if predictor and predictor.best_model is not None:
                    logger.info("ğŸ¯ CrÃ©ation de l'analyse de performance...")
                    try:
                        processor = ElectionDataProcessor()
                        X, y = processor.prepare_ml_features(processed_df)
                        if not X.empty and not y.empty:
                            perf_analysis = analyzer.create_performance_dashboard(predictor, X, y)
                            if perf_analysis:
                                analyses_results['performance'] = perf_analysis
                                logger.info("âœ… Analyse de performance crÃ©Ã©e")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Analyse performance Ã©chouÃ©e: {e}")
                
                # GÃ©nÃ©ration du rapport HTML
                if analyses_results:
                    logger.info("ğŸ“‹ GÃ©nÃ©ration du rapport final...")
                    try:
                        report_path = analyzer.generate_report(analyses_results)
                        
                        print("\n" + "=" * 60)
                        print("ğŸ“Š ANALYSES CRÃ‰Ã‰ES")
                        print("=" * 60)
                        
                        total_plots = 0
                        for analysis_name, results in analyses_results.items():
                            plots = results.get('plots_created', [])
                            total_plots += len(plots)
                            print(f"ğŸ”¸ {analysis_name:15} | {len(plots)} visualisation(s)")
                            for plot in plots:
                                print(f"   ğŸ“„ {plot}")
                        
                        print(f"\nâœ… Total visualisations: {total_plots}")
                        print(f"ğŸ“ RÃ©pertoire: visualizations/")
                        
                        if report_path:
                            print(f"ğŸ“‹ Rapport complet: {report_path}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ GÃ©nÃ©ration rapport Ã©chouÃ©e: {e}")
                
                else:
                    logger.warning("âš ï¸ Aucune analyse n'a pu Ãªtre crÃ©Ã©e")
                
            except Exception as e:
                logger.error(f"âŒ Erreur lors de l'analyse: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        # 4. PRÃ‰DICTIONS
        if args.predict:
            logger.info("=" * 40)
            logger.info("ğŸ”® Ã‰TAPE 4: PRÃ‰DICTIONS")
            logger.info("=" * 40)
            
            try:
                # Chargement du modÃ¨le
                if predictor is None:
                    predictor = ElectionPredictor()
                    predictor.load_model('best_election_model.pkl')
                
                # PrÃ©paration des donnÃ©es pour prÃ©diction
                processor = ElectionDataProcessor()
                X, y = processor.prepare_ml_features(processed_df)
                
                if not X.empty:
                    # PrÃ©diction sur un Ã©chantillon
                    sample_size = min(10, len(X))
                    sample_X = X.sample(n=sample_size, random_state=42)
                    
                    predictions, probabilities = predictor.predict(sample_X)
                    
                    print(f"\nğŸ”® EXEMPLES DE PRÃ‰DICTIONS ({sample_size} Ã©chantillons)")
                    print("-" * 60)
                    
                    for i, idx in enumerate(sample_X.index):
                        pred = predictions[i]
                        conf_str = ""
                        
                        if probabilities is not None:
                            confidence = probabilities[i].max()
                            conf_str = f" (confiance: {confidence:.1%})"
                        
                        # DÃ©coder la prÃ©diction si nÃ©cessaire
                        if hasattr(predictor, 'label_encoders') and 'winner' in predictor.label_encoders:
                            try:
                                pred_decoded = predictor.label_encoders['winner'].inverse_transform([pred])[0]
                                print(f"ğŸ¯ Ã‰chantillon {idx:3d}: {pred_decoded}{conf_str}")
                            except:
                                print(f"ğŸ¯ Ã‰chantillon {idx:3d}: Classe {pred}{conf_str}")
                        else:
                            print(f"ğŸ¯ Ã‰chantillon {idx:3d}: {pred}{conf_str}")
                    
                    # Statistiques des prÃ©dictions
                    if probabilities is not None:
                        avg_confidence = probabilities.max(axis=1).mean()
                        high_conf_count = (probabilities.max(axis=1) > 0.8).sum()
                        
                        print(f"\nğŸ“Š Statistiques des prÃ©dictions:")
                        print(f"   - Confiance moyenne: {avg_confidence:.1%}")
                        print(f"   - PrÃ©dictions haute confiance (>80%): {high_conf_count}/{sample_size}")
                
                else:
                    logger.error("âŒ Impossible de prÃ©parer les donnÃ©es pour la prÃ©diction")
                
            except Exception as e:
                logger.error(f"âŒ Erreur lors des prÃ©dictions: {e}")
                logger.info("ğŸ’¡ Assurez-vous qu'un modÃ¨le a Ã©tÃ© entraÃ®nÃ© (--train)")
        
        # RÃ©sumÃ© final
        logger.info("=" * 60)
        logger.info("âœ… PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
        logger.info("=" * 60)
        
        # Statistiques finales
        if processed_df is not None:
            print(f"\nğŸ“Š RÃ‰SUMÃ‰ FINAL")
            print("-" * 30)
            print(f"ğŸ“‹ Enregistrements traitÃ©s: {len(processed_df):,}")
            print(f"ğŸ›ï¸ DÃ©partements couverts: {processed_df['departement'].nunique()}")
            print(f"ğŸ“… AnnÃ©es disponibles: {sorted(processed_df['annee'].unique())}")
            print(f"ğŸ­ Nuances politiques: {processed_df['nuance'].nunique()}")
        
        print(f"\nğŸ“ Fichiers gÃ©nÃ©rÃ©s:")
        print(f"   - DonnÃ©es: data/processed/")
        if args.train:
            print(f"   - ModÃ¨les: models/")
        if args.analyze:
            print(f"   - Visualisations: visualizations/")
        print(f"   - Logs: election_predictor.log")
        
        print(f"\nğŸš€ Ã‰tapes suivantes:")
        print(f"   - Lancez: streamlit run app.py")
        print(f"   - Ouvrez: http://localhost:8501")
        
        logger.info(f"ğŸ‰ Pipeline terminÃ© pour l'utilisateur: mgaisnon")
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Pipeline interrompu par l'utilisateur")
        print("\nâ¹ï¸ Pipeline interrompu.")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Erreur fatale dans le pipeline: {e}")
        import traceback
        logger.error(traceback.format_exc())
        print(f"\nâŒ Erreur fatale: {e}")
        print("ğŸ“‹ Consultez le fichier election_predictor.log pour plus de dÃ©tails")
        raise

if __name__ == "__main__":
    main()