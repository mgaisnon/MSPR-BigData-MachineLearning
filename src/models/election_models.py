import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib
import logging
from pathlib import Path
import sys
from typing import Dict, Tuple
import warnings
warnings.filterwarnings('ignore')

# Configuration du chemin
current_dir = Path(__file__).parent
root_dir = current_dir.parent.parent
sys.path.insert(0, str(root_dir))

logger = logging.getLogger(__name__)

class ElectionPredictor:
    """Classe pour les pr√©dictions √©lectorales avec Machine Learning"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        self.best_model_name = None
        self.best_score = 0
        self._last_results = {}
        
        logger.info("ElectionPredictor initialis√©")
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """Pr√©pare les features pour le Machine Learning"""
        try:
            logger.info(f"Pr√©paration des features pour {len(df)} enregistrements")
            
            data = df.copy()
            
            # D√©finir le target (ce qu'on veut pr√©dire)
            if 'famille_politique' in data.columns:
                target = data['famille_politique'].copy()
                logger.info("Target: famille_politique")
            elif 'nuance' in data.columns:
                target = data['nuance'].copy()
                logger.info("Target: nuance")
            else:
                raise ValueError("Pas de colonne target trouv√©e")
            
            # Cr√©er le DataFrame des features
            features_df = pd.DataFrame()
            
            # Features temporelles
            if 'annee' in data.columns:
                features_df['annee'] = data['annee']
                features_df['decennie'] = (data['annee'] // 10) * 10
                features_df['depuis_2000'] = (data['annee'] - 2000).clip(lower=0)
            
            # Features g√©ographiques
            if 'departement' in data.columns:
                dept_encoder = LabelEncoder()
                features_df['departement_encoded'] = dept_encoder.fit_transform(data['departement'].astype(str))
                self.encoders['departement'] = dept_encoder
            
            if 'typologie' in data.columns:
                features_df['is_urbain'] = (data['typologie'] == 'Urbain').astype(int)
            
            if 'ancien_midi_pyrenees' in data.columns:
                features_df['ancien_midi_pyrenees'] = data['ancien_midi_pyrenees'].astype(int)
            
            # Features √©lectorales (num√©riques)
            numeric_features = ['taux_participation', 'taux_abstention', 'voix', 'inscrits', 'votants']
            
            for feature in numeric_features:
                if feature in data.columns:
                    features_df[feature] = pd.to_numeric(data[feature], errors='coerce').fillna(0)
            
            # Features d√©riv√©es
            if all(col in features_df.columns for col in ['voix', 'inscrits']):
                features_df['influence'] = features_df['voix'] / (features_df['inscrits'] + 1)
            
            if 'taux_participation' in features_df.columns:
                features_df['participation_haute'] = (features_df['taux_participation'] > 70).astype(int)
                features_df['participation_faible'] = (features_df['taux_participation'] < 50).astype(int)
            
            # Tour (si disponible)
            if 'tour' in data.columns:
                features_df['tour'] = data['tour']
            
            # Nettoyer les donn√©es
            features_df = features_df.fillna(0)
            
            # Encoder le target
            target_encoder = LabelEncoder()
            target_encoded = target_encoder.fit_transform(target.astype(str).fillna('Inconnu'))
            self.encoders['target'] = target_encoder
            
            logger.info(f"Features cr√©√©es: {list(features_df.columns)}")
            logger.info(f"Nombre de classes target: {len(target_encoder.classes_)}")
            logger.info(f"√âchantillons finaux: {len(features_df)}")
            
            return features_df, pd.Series(target_encoded)
            
        except Exception as e:
            logger.error(f"Erreur pr√©paration features: {e}")
            # Fallback simple
            fallback_df = pd.DataFrame({
                'dummy_feature': range(len(df)),
                'random_feature': np.random.random(len(df))
            })
            fallback_target = pd.Series([0] * len(df))
            return fallback_df, fallback_target
    
    def train_models(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """Entra√Æne les mod√®les de Machine Learning"""
        try:
            logger.info("ü§ñ D√©but de l'entra√Ænement des mod√®les ML")
            
            # V√©rifications pr√©liminaires
            if len(X) < 20:
                return {"error": "Pas assez de donn√©es pour l'entra√Ænement (minimum 20)"}
            
            unique_classes = len(np.unique(y))
            if unique_classes < 2:
                return {"error": f"Pas assez de classes diff√©rentes ({unique_classes})"}
            
            logger.info(f"Donn√©es: {len(X)} √©chantillons, {len(X.columns)} features, {unique_classes} classes")
            
            # Division train/test
            test_size = min(0.3, max(0.1, 50/len(X)))  # Adaptatif selon la taille
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
            
            logger.info(f"Train: {len(X_train)}, Test: {len(X_test)}")
            
            # Configuration des mod√®les
            models_to_train = {
                'RandomForest': {
                    'model': RandomForestClassifier(
                        n_estimators=100, 
                        max_depth=10,
                        random_state=42, 
                        n_jobs=-1
                    ),
                    'needs_scaling': False
                },
                'LogisticRegression': {
                    'model': LogisticRegression(
                        random_state=42, 
                        max_iter=1000,
                        C=1.0
                    ),
                    'needs_scaling': True
                }
            }
            
            results = {}
            
            # Entra√Ænement de chaque mod√®le
            for model_name, config in models_to_train.items():
                try:
                    logger.info(f"‚ö° Entra√Ænement {model_name}...")
                    
                    model = config['model']
                    
                    # Gestion du scaling pour la r√©gression logistique
                    if config['needs_scaling']:
                        scaler = StandardScaler()
                        X_train_processed = scaler.fit_transform(X_train)
                        X_test_processed = scaler.transform(X_test)
                        self.scalers[model_name] = scaler
                    else:
                        X_train_processed = X_train
                        X_test_processed = X_test
                    
                    # Entra√Ænement
                    model.fit(X_train_processed, y_train)
                    
                    # Pr√©dictions
                    y_pred = model.predict(X_test_processed)
                    accuracy = accuracy_score(y_test, y_pred)
                    
                    # Stockage du mod√®le
                    self.models[model_name] = model
                    
                    # Feature importance (pour RandomForest)
                    feature_importance = None
                    if hasattr(model, 'feature_importances_'):
                        importance_df = pd.DataFrame({
                            'feature': X.columns,
                            'importance': model.feature_importances_
                        }).sort_values('importance', ascending=False)
                        feature_importance = importance_df.to_dict('records')
                    
                    # R√©sultats
                    results[model_name] = {
                        'accuracy': accuracy,
                        'n_train': len(X_train),
                        'n_test': len(X_test),
                        'n_features': len(X.columns),
                        'n_classes': unique_classes,
                        'feature_importance': feature_importance
                    }
                    
                    # Suivre le meilleur mod√®le
                    if accuracy > self.best_score:
                        self.best_score = accuracy
                        self.best_model_name = model_name
                    
                    logger.info(f"‚úÖ {model_name}: Accuracy = {accuracy:.4f}")
                    
                except Exception as model_error:
                    logger.error(f"‚ùå Erreur {model_name}: {model_error}")
                    results[model_name] = {'error': str(model_error)}
            
            # Sauvegarde des r√©sultats
            self._last_results = results
            
            # Sauvegarde des mod√®les
            self.save_models()
            
            logger.info(f"üèÜ Meilleur mod√®le: {self.best_model_name} (accuracy: {self.best_score:.4f})")
            
            return results
            
        except Exception as e:
            logger.error(f"Erreur g√©n√©rale entra√Ænement: {e}")
            return {"error": str(e)}
    
    def predict_election(self, features: Dict, model_name: str = None) -> Dict:
        """Fait une pr√©diction pour de nouvelles donn√©es"""
        try:
            if not self.models:
                return {"error": "Aucun mod√®le entra√Æn√© disponible"}
            
            # Utiliser le meilleur mod√®le par d√©faut
            model_name = model_name or self.best_model_name or list(self.models.keys())[0]
            
            if model_name not in self.models:
                return {"error": f"Mod√®le {model_name} non trouv√©"}
            
            model = self.models[model_name]
            
            # Pr√©parer les donn√©es
            features_df = pd.DataFrame([features])
            
            # Appliquer le scaling si n√©cessaire
            if model_name in self.scalers:
                features_processed = self.scalers[model_name].transform(features_df)
            else:
                features_processed = features_df
            
            # Pr√©diction
            prediction = model.predict(features_processed)[0]
            
            # Probabilit√©s (si disponible)
            probabilities = None
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(features_processed)[0]
                if 'target' in self.encoders:
                    classes = self.encoders['target'].classes_
                    probabilities = {classes[i]: float(proba[i]) for i in range(len(classes))}
            
            # D√©coder la pr√©diction
            if 'target' in self.encoders:
                predicted_class = self.encoders['target'].inverse_transform([prediction])[0]
            else:
                predicted_class = str(prediction)
            
            result = {
                'predicted_class': predicted_class,
                'confidence': float(max(proba)) if probabilities else 0.5,
                'probabilities': probabilities,
                'model_used': model_name
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Erreur pr√©diction: {e}")
            return {"error": str(e)}
    
    def save_models(self):
        """Sauvegarde tous les mod√®les entra√Æn√©s"""
        try:
            # Import de la config
            from config.config import MODEL_CONFIG
            models_dir = MODEL_CONFIG.models_dir
            models_dir.mkdir(exist_ok=True, parents=True)
            
            # Sauvegarder chaque mod√®le
            for model_name, model in self.models.items():
                model_file = models_dir / f"{model_name.lower()}_model.joblib"
                joblib.dump(model, model_file)
                logger.info(f"üíæ Mod√®le {model_name} sauvegard√©: {model_file}")
            
            # Sauvegarder les scalers
            if self.scalers:
                scalers_file = models_dir / "scalers.joblib"
                joblib.dump(self.scalers, scalers_file)
                logger.info(f"üíæ Scalers sauvegard√©s: {scalers_file}")
            
            # Sauvegarder les encoders
            if self.encoders:
                encoders_file = models_dir / "encoders.joblib"
                joblib.dump(self.encoders, encoders_file)
                logger.info(f"üíæ Encoders sauvegard√©s: {encoders_file}")
            
            # M√©tadonn√©es
            metadata = {
                'best_model_name': self.best_model_name,
                'best_score': self.best_score,
                'models_list': list(self.models.keys()),
                'last_results': self._last_results
            }
            metadata_file = models_dir / "metadata.joblib"
            joblib.dump(metadata, metadata_file)
            logger.info(f"üíæ M√©tadonn√©es sauvegard√©es: {metadata_file}")
            
        except Exception as e:
            logger.error(f"Erreur sauvegarde: {e}")
    
    def load_models(self):
        """Charge les mod√®les pr√©c√©demment sauvegard√©s"""
        try:
            from config.config import MODEL_CONFIG
            models_dir = MODEL_CONFIG.models_dir
            
            metadata_file = models_dir / "metadata.joblib"
            if not metadata_file.exists():
                logger.warning("Aucune sauvegarde de mod√®les trouv√©e")
                return False
            
            # Charger les m√©tadonn√©es
            metadata = joblib.load(metadata_file)
            self.best_model_name = metadata.get('best_model_name')
            self.best_score = metadata.get('best_score', 0)
            self._last_results = metadata.get('last_results', {})
            
            # Charger chaque mod√®le
            for model_name in metadata.get('models_list', []):
                model_file = models_dir / f"{model_name.lower()}_model.joblib"
                if model_file.exists():
                    self.models[model_name] = joblib.load(model_file)
                    logger.info(f"üìÇ Mod√®le {model_name} charg√©")
            
            # Charger scalers et encoders
            scalers_file = models_dir / "scalers.joblib"
            if scalers_file.exists():
                self.scalers = joblib.load(scalers_file)
                logger.info("üìÇ Scalers charg√©s")
            
            encoders_file = models_dir / "encoders.joblib"
            if encoders_file.exists():
                self.encoders = joblib.load(encoders_file)
                logger.info("üìÇ Encoders charg√©s")
            
            logger.info("‚úÖ Tous les mod√®les charg√©s avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"Erreur chargement: {e}")
            return False
    
    def get_model_performance(self) -> Dict:
        """Retourne les performances des mod√®les"""
        return self._last_results
    
    def get_available_models(self) -> list:
        """Retourne la liste des mod√®les disponibles"""
        return list(self.models.keys())

# Fonction utilitaire pour l'int√©gration avec main.py
def train_election_models(processed_data_file: str = None):
    """
    Fonction principale pour entra√Æner les mod√®les
    Utilis√©e par main.py dans l'√©tape pr√©dictions
    """
    try:
        from config.config import DATA_CONFIG
        
        # Fichier par d√©faut
        if processed_data_file is None:
            processed_data_file = DATA_CONFIG.processed_data_dir / 'elections_processed.csv'
        
        # V√©rifier l'existence du fichier
        if not Path(processed_data_file).exists():
            return None, {"error": f"Fichier non trouv√©: {processed_data_file}"}
        
        # Charger les donn√©es
        data = pd.read_csv(processed_data_file)
        logger.info(f"üìä Donn√©es charg√©es: {len(data)} enregistrements")
        
        # V√©rifications de base
        if len(data) < 20:
            return None, {"error": "Pas assez de donn√©es (minimum 20 enregistrements)"}
        
        # Cr√©er et configurer le pr√©dicteur
        predictor = ElectionPredictor()
        
        # Pr√©parer les features
        X, y = predictor.prepare_features(data)
        
        # Entra√Æner les mod√®les
        if len(X) >= 20 and len(np.unique(y)) >= 2:
            results = predictor.train_models(X, y)
            return predictor, results
        else:
            return predictor, {"error": "Donn√©es insuffisantes pour l'entra√Ænement ML"}
            
    except Exception as e:
        logger.error(f"Erreur train_election_models: {e}")
        return None, {"error": str(e)}

# Test du module (si lanc√© directement)
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    print("üß™ TEST DU MODULE MACHINE LEARNING")
    print("=" * 50)
    
    # Test avec des donn√©es fictives
    test_data = pd.DataFrame({
        'annee': [2017, 2017, 2022, 2022] * 10,
        'departement': [30, 31, 30, 31] * 10,
        'famille_politique': ['Droite', 'Gauche', 'Centre', 'Droite'] * 10,
        'voix': [1000, 1500, 800, 1200] * 10,
        'inscrits': [2000, 2000, 2000, 2000] * 10,
        'taux_participation': [65.5, 70.2, 60.1, 75.3] * 10,
        'typologie': ['Urbain', 'Rural', 'Urbain', 'Rural'] * 10,
        'ancien_midi_pyrenees': [0, 1, 0, 1] * 10
    })
    
    print(f"Donn√©es test: {len(test_data)} enregistrements")
    
    predictor = ElectionPredictor()
    X, y = predictor.prepare_features(test_data)
    print(f"Features: {X.shape}, Target: {y.shape}")
    
    results = predictor.train_models(X, y)
    print("\nR√©sultats:")
    for model_name, result in results.items():
        if 'accuracy' in result:
            print(f"  {model_name}: {result['accuracy']:.4f}")
        else:
            print(f"  {model_name}: {result}")
    
    print("\n‚úÖ Test termin√©")